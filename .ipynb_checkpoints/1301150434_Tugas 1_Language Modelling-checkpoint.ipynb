{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> PROBABILISTIC LANGUAGE MODELLING WITH BIGRAM MODEL </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nama : Chlaudiah Julinar S.L\n",
    "<br>\n",
    "NIM : 1301150434\n",
    "<br>\n",
    "Kelas : ICM - 39 - GAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> PREPARATION </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import NLTK Tools for Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langkah-langkah:\n",
    "1. Menyiapkan sebuah array untuk menampung setiap line pada file\n",
    "2. Membuka file dengan mendefinisikan nama file dan encoding utf-8 agar dapat di decode \n",
    "3. File yang sudah dibuka, dibaca tiap line nya dan di simpan kedalam sebuah variabel\n",
    "4. Memasukkan setiap line pada variabel penampung kedalam array yang telah disiapkan\n",
    "6. Setelah file sudah selesai dibaca, maka file akan ditutup\n",
    "7. Mengembalikan array yang sudah terisi oleh setiap line dari file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_artikel(namafile):\n",
    "    data = [] #Langkah 1\n",
    "    artikel = open(namafile,encoding=\"utf-8\") #Langkah 2\n",
    "    data_artikel = artikel.readlines() #Langkah 3\n",
    "    for i in range(len(data_artikel)): \n",
    "        data.append(data_artikel[i].lower()) # Langkah 4\n",
    "    artikel.close() #Langkah 5\n",
    "    return data #Langkah 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TOKENIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization adalah proses ketika diberikan suatu urutan karakter dan unit dokumen yang ditentukan, maka proses tokenization akan melakukan pemotongan terhadap urutan karakter tersebut menjadi beberapa bagian yang disebut dengan **tokens** dan pada saat tertentu juga dapat membuang karakter tertentu. (from: https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html)\n",
    "Contoh: \n",
    "<center> ![](files/tokenization example.JPG) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langkah-langkah:\n",
    "1. Menyiapkan array baru untuk menampung hasil tokenisasi\n",
    "2. Dalam setiap line yang terdapat dalam array file, array tokenization akan diisi dengan hasil tokenisasi untuk setiap line pada array file\n",
    "3. Mengembalikan array hasil tokenisasi agar dapat digunakan untuk tahap selanjutnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(data):\n",
    "    tokenization=[] #Langkah 1\n",
    "    for i in data:\n",
    "        tokenization.append(nltk.word_tokenize(i)) #Langkah 2\n",
    "    return tokenization #Langkah 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Unigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram model yaitu salah satu **language modelling** dimana pada unigram model tidak memperhitungkan keterhubungan antar kata. Pada unigram model, probability hanya memperhitungkan jumlah kemunculan dari satu kata saja. Rumus:\n",
    "<center> ![](files/unigram.JPG) </center>\n",
    "Jumlah kemunculan tiap kata pada unigram model akan digunakan pada perhitungan probability kemunculan kata pada bigram model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langkah-langkah:\n",
    "1. Menyiapkan dictionary untuk menampung hasil perhitungan frekuensi kemunculan tiap kata pada array file\n",
    "2. Menyiapkan counter untuk menghitung jumlah kata dalam dictionary\n",
    "3. Karena hasil tokenization menghasilkan sebuah list, maka terlebih dahulu harus melakukan looping didalam list untuk mengetahui informasi line pada array tokenization\n",
    "4. Setelah itu, dapat dilakukan looping didalam informasi line tersebut untuk mendapatkan informasi mengenai token dari tiap line\n",
    "5. Selama proses looping:\n",
    "    * jika token sudah terdapat dalam dictionary sebagai key maka hanya perlu melakukan penambahan jumlah token tersebut dalam dictionary\n",
    "    * jika token tidak ada, maka dilakukan penambahan token tersebut kedalam dictionary sebagai key dengan jumlah token di inisialisasi dengan 1\n",
    "    * lakukan increment terhadap counter\n",
    "6. Mengembalikan dictionary yang menampung jumlah kemunculan tiap token dan jumlah kata dalam dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unigram(tokenization):\n",
    "    freq_unigram = {} #Langkah 1\n",
    "    counter_unigram = 0 #Langkah 2\n",
    "    for tokenize in tokenization: #Langkah 3\n",
    "        for token in tokenize: #Langkah 4\n",
    "            if token in freq_unigram: \n",
    "                freq_unigram[token] += 1 #Langkah 5a\n",
    "            else:\n",
    "                freq_unigram[token] = 1 #Langkah 5b\n",
    "            counter_unigram += 1 #Langkah 5c\n",
    "    return freq_unigram, counter_unigram #Langkah 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Bigram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jika pada unigram model probability hanya memperhatikan kata itu sendiri, bigram model adalah sebaliknya. Pada bigram model, untuk menentukan probability kemunculan suatu kata harus memperhatikan kata sebelumnya. Sehingga, bigram model dapat menghasilkan language modelling yang lebih baik dari pada unigram model pada saat ingin melakukan random sentence atau random words generator. Rumus:\n",
    "<center> ![](files/bigram.JPG) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langkah-langkah:\n",
    "1. Menyiapkan dictionary untuk menampung hasil perhitungan frekuensi kemunculan tiap kata pada array file\n",
    "2. Menyiapkan counter untuk menghitung jumlah kata dalam dictionary\n",
    "3. Karena hasil tokenization menghasilkan sebuah list, maka terlebih dahulu harus melakukan looping didalam list untuk mengetahui informasi line pada array tokenization\n",
    "4. Setelah itu, dapat dilakukan looping terhadap indeks array didalam informasi line tersebut untuk mendapatkan informasi mengenai token dari tiap line\n",
    "5. Selama proses looping:\n",
    "    * jika indeks array masih lebih kecil dari panjang array, maka:\n",
    "    (a) jika token dengan indeks ke i dan i+1 sudah ada pada dictionary, maka untuk value pada dictionary dengan key yaitu token indeks ke-i,token indeks ke-i+1 akan dilakukan proses increment pada jumlah key tersebut\n",
    "    (b) jika belum ada, maka key dengan indeks-i,indeks-i+1 akan ditambahkan sebagai key dalam dictionary dengan jumlah yaitu 1\n",
    "    * lakukan increment pada counter untuk menghitung jumlah kata dalam dictionary\n",
    "6. Mengembalikan dictionary yang menampung jumlah kemunculan tiap token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram(tokenization):\n",
    "    freq_bigram={} #Langkah 1\n",
    "    count_bigram = 0 #Langkah 2\n",
    "    for token in tokenization: #Langkah 3\n",
    "        for i in range(len(token)): #Langkah 4\n",
    "            if i < len(token) - 1: #Langkah 5\n",
    "                if (token[i],token[i+1]) in freq_bigram: #Langkah 5.1\n",
    "                    freq_bigram[(token[i],token[i+1])] += 1 #Langkah 5.1.a\n",
    "                else:\n",
    "                    freq_bigram[(token[i],token[i+1])] = 1 #Langkah 5.1.b\n",
    "                count_bigram+=1 #Langkah 5b\n",
    "    return freq_bigram #Langkah 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimasi Probabilitas Bigram Model with Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk melakukan estimasi probabilitas suatu bigram model, diperlukan informasi dari unigram model yaitu jumlah kemunculan kata sebelumnya. Rumus:\n",
    "<center> ![](files/probability bigram.JPG) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tetapi, bisa saja dalam proses estimasi probabilitas akan menghasilkan nilai 0 karena pada saat pengujian terdapat beberapa kata atau pasangan kata yang tidak terdapat dalam corpus yang dibangun. Maka dari itu, diperlukan proses smoothing atau generalisasi terhadap corpus agar dapat mengatasi masalah probabilitas 0 tersebut. Pada program ini menggunakan dua cara proses smoothing yaitu:\n",
    "1. Laplace Smoothing (add-one)\n",
    "Pada laplace smoothing, semua kemungkinan yang terjadi akan diberikan nilai 1 sehingga jumlah tiap token dalam dictionary tidak akan ada nilai 0. Rumus sebagai berikut:\n",
    "<center> ![](files/laplace.JPG) </center>\n",
    "2. Reconstituted Count (cstar)\n",
    "Pada cstar, setiap jumlah tiap token dalam dictionary akan diberi pengurangan (diskon) lalu nilai diskon tersebut akan di distribusikan terhadap jumlah kemungkinan kemunculan token yang bernilai 0. Dengan catatan, hasil penjumlahan seluruh kata sebelum dilakukan diskon dan distribusi dengan hasil penjumlahan seluruh kata setelah proses distribusi haruslah **sama**. Rumus sebagai berikut:\n",
    "<center> ![](files/cstar.JPG) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langkah-langkah:\n",
    "1. Menyiapkan dictionary yang akan menampung nilai probabilitas dengan proses laplace smoothing\n",
    "2. Menyiapkan dictionary yang akan menampung nilai probabilitas dengan proses reconstituted counts\n",
    "3. Lakukan perulangan terhadap key dalam dictionary kemunculan jumlah kata bigram model sebelumnya\n",
    "4. Selama proses looping:\n",
    "    * masukkan token pertama (kata pertama) yang ada pada dictionary key kedalam sebuah variabel a\n",
    "    * masukkan token kedua (kata kedua) yang ada pada dictionary key kedalam sebuah variabel b\n",
    "    * lakukan perhitungan terhadap probability dengan menggunakan rumus laplace smoothing, yaitu (jumlah kemunculan kata dari suatu key pada dictionary bigram model + 1) / (jumlah kemunculan kata pertama dari suatu key pada dictionary unigram model + jumlah keseluruhan kata pada dictionary unigram model) . Lalu, masukkan nilai perhitungan tersebut kedalam dictionary yang menampung nilai probabilitas laplace smoothing dengan key tersebut\n",
    "    * lakukan perhitungan terhadap probability dengan menggunakan rumus cstar, yaitu ((jumlah kemunculan kata dari suatu key pada dict bigram model + 1) * jumlah kemunculan kata pertama pada dict unigram model) / (jumlah kemunculan kata pertama dari suatu key pada dictionary unigram model + jumlah keseluruhan kata pada dictionary unigram model) . Lalu, masukkan nilai perhitungan tersebut kedalam dictionary yang menampung nilai probabilitas cstar dengan key tersebut\n",
    "5. Mengembalikan nilai perhitungan probability laplace smoothing dan cstar agar dapat digunakan pada tahap pengujian\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probBigramSmoothing(freq_bigram, freq_unigram):\n",
    "    prob_bigramSmooth = {} #Langkah 1\n",
    "    cstar_bigram = {} #Langkah 2\n",
    "    for bigram in freq_bigram: #Langkah 3\n",
    "        kata1 = bigram[0] #Langkah 4a\n",
    "        kata2 = bigram[1] #Langkah 4b\n",
    "        prob_bigramSmooth[bigram] = (freq_bigram.get(bigram) + 1) / (freq_unigram.get(kata1) + len(freq_unigram)) ##Add-one smoothing (4c)\n",
    "        cstar_bigram[bigram] = (freq_bigram[bigram]+1) * freq_unigram[kata1] / (freq_unigram[kata1] + len(freq_unigram)) #Cstar (4d)\n",
    "    return prob_bigramSmooth, cstar_bigram #Langkah 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> PENGUJIAN </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informasi Corpus\n",
    "1. Topik yang saya ambil sebagai acuan topik corpus saya adalah Artificial Intelligence atau Kecerdasan Buatan. Alasan saya memilih topik ini adalah karena pada tugas diminta untuk mencari berbagai artikel mengenai topik corpus maka dengan membaca artikel mengenai kecerdasan buatan, dapat sekaligus membantu saya dalam mengetahui sejauh mana perkembangan teknologi kecerdasan buatan sudah diterapkan di setiap negara, terutama di Indonesia.\n",
    "2. Sumber artikel yang saya gunakan sebagian besar adalah berasal dari website online layanan berita contohnya CNN Indonesia, SindoNew, Tempo, Kompas, Medium, TheConversation, Kompasiana, dan Republika.\n",
    "3. Total seluruh jumlah artikel yang digunakan dalam membangun corpus adalah 100 artikel berbahasa indonesia.\n",
    "4. 100 artikel tersebut disimpan dalam satu file dengan tipe **.txt** dengan tiap line menandakan artikel ke-1, 2, 3, ... , 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membangun Corpus\n",
    "1. Membaca file artikel dengan memanggil fungsi read file yaitu **read_artikel(namafile)**\n",
    "2. Melakukan proses tokenization dengan memanggil fungsi tokenization yaitu **get_token(data)**\n",
    "3. Membangun unigram model dari hasil tokenisasi pada langkah 2, dengan memanggil fungsi **get_unigram(tokenization)**\n",
    "4. Membangun bigram model dari hasil tokenisasi pada langkah 2, dengan memanggil fungsi **get_bigram(tokenization)**\n",
    "5. Menghitung nilai probability berdasarkan laplace smoothing dan reconstituted counts terhadap hasil bigram model dan unigram model, dengan memanggil fungsi **get_probBigramSmoothing(freq_bigram, freq_unigram)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_artikel('Article about AI.txt') #Langkah 1\n",
    "tokenization = get_token(data) #Langkah 2\n",
    "freq_unigram, counter_unigram = get_unigram(tokenization) #Langkah 3\n",
    "freq_bigram = get_bigram(tokenization) #Langkah 4\n",
    "prob_bigram, cstar_bigram = get_probBigramSmoothing(freq_bigram, freq_unigram) #Langkah 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Word Generator\n",
    "Pada tahap ini akan dilakukan pengujian prediksi kemunculan kata, dimana kata yang muncul adalah kata yang memiliki probabilitas kemunculan kata paling tinggi pada probabilitas laplace smoothing atau cstar. Contoh: \n",
    "* Input word : Saya suka\n",
    "* Processing : [(suka, makan): 0.1 , (suka, tidur) : 0.5, (suka, belajar) : 0.01)]\n",
    "* Output : tidur\n",
    "* Kalimat bentukan : saya suka tidur\n",
    "\n",
    "10 kata yang akan di uji adalah : \n",
    "1. Kata **artificial**\n",
    "2. Kata **kecerdasan**\n",
    "3. Kata **neural**\n",
    "4. Kata **manusia**\n",
    "5. Kata **tidur**\n",
    "6. Kata **makan**\n",
    "7. Kata **ayam**\n",
    "8. Kata **tahu**\n",
    "9. Kata **merupakan**\n",
    "10. Kata **teknologi**\n",
    "\n",
    "Alasan Pemilihan Kata:\n",
    "* Alasan pemilihan kata 1, 2, dan 3 karena ketiga kata tersebut memiliki kata lanjutan yang seharusnya sudah sangat tergambarkan dalam topik artikel.\n",
    "* Alasan pemilihan kata 4, 5, 6, 7 karena ke-4 kata tersebut adalah kata yang memiliki cakupan terlalu luas untuk kata 4 dan cakupan terlalu sempit untuk kata 5, 6, 7 dan 4 kata ini cukup sulit untuk diperhatikan satu persatu didalam artikel\n",
    "* Alasan pemilihan kata 9 dan 10 karena kedua kata cukup banyak digunakan pada setiap artikel yang membahas mengenai teknologi seperti contoh corpus yang dibangun ini, sehingga dapat diketahui kata yang paling sering muncul setelah kata general tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langkah - langkah:\n",
    "1. Menerima inputan kalimat dari user minimal 2 kata agar dapat dilakukan bigram model pada kalimat inputan tersebut\n",
    "2. Melakukan generalisasi kalimat menjadi seluruhnya huruf kecil\n",
    "3. Selama proses pembentukan bigram model:\n",
    "    * kalimat dengan indeks-i dan indeks-i+1 digabungkan menjadi satu\n",
    "    * kalimat dengan indeks-i dan indeks-i+1 akan menjadi isi di dalam indeks baru pada array yang menampung hasil bigram model\n",
    "4. Menampilkan array yang menampung hasil bigram model pada inputan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masukkan kalimat (min.2 kata): apakah pada zaman ini artificial\n",
      "[('apakah', 'pada'), ('pada', 'zaman'), ('zaman', 'ini'), ('ini', 'artificial')]\n"
     ]
    }
   ],
   "source": [
    "input_words = []\n",
    "input_test = input('Masukkan kalimat (min.2 kata): ') #Langkah 1\n",
    "input_test = input_test.lower() #Langkah 2\n",
    "for i in range(len(input_test.split()) - 1):\n",
    "    input_words.append((input_test.split()[i], input_test.split()[i+1])) #Langkah 3a dan 3b\n",
    "print(input_words) #Langkah 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langkah - langkah:\n",
    "1. Mengambil seluruh keys yang ada pada dictionary probability bigram with laplace smoothing dan disimpan kedalam variable\n",
    "2. Mengambil indeks terakhir pada array hasil bigram model inputan, karena kata yang ingin diuji berada pada indeks terakhir dari array hasil bigram model inputan\n",
    "3. Setelah itu, indeks terakhir yang terdiri atas 2 kata akan diambil kata terakhir pada indeks tersebut karena kata yang ingin diuji adalah kemunculan kata setelah kata terakhir pada indeks terakhir\n",
    "4. Lakukan looping terhadap setiap key didalam variable yang berisi seluruh keys yang ada pada dictionary bigram model\n",
    "5. Selama proses looping:\n",
    "    * Lakukan pengecekan terhadap kesamaan kata pertama didalam key dengan kata terakhir pada langkah ke-3, jika sama maka: \n",
    "    (a) masukkan setiap kata kedua pada key ke dalam sebuah array yang akan menampung seluruh kata kedua dari kata pertama key yang sama\n",
    "    (b) masukkan setiap nilai probabilitas dari key tersebut ke dalam sebuah array yang akan menampung seluruh nilai probabilitas dari kata pertama key yang sama\n",
    "6. Lakukan looping pada array yang menampung nilai probabilitas dari langkah sebelumnya untuk menemukan kata dengan nilai probabilitas yang paling besar\n",
    "7. Tampilkan array yang menampung seluruh kata kedua dari langkah 5a, dan array yang menampung seluruh nilai probabilitas key dari langkah 5b\n",
    "8. Tampilkan kata yang dipilih dengan nilai probabilitas dari langkah 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial\n",
      "['intelligence', 'intelligent', 'neural', 'inteligence', 'intelligence/ai', 'intellegence', 'intelligence/', 'intelligencce', 'intellige', 'intelegent', 'intelligence/kecerdasan', '(', 'ini']\n",
      "[0.009554140127388535, 0.00030330603579011223, 0.00045495905368516835, 0.00045495905368516835, 0.001213224143160449, 0.0009099181073703367, 0.0007582650894752805, 0.00030330603579011223, 0.00030330603579011223, 0.00045495905368516835, 0.00030330603579011223, 0.00030330603579011223, 0.00030330603579011223]\n",
      "Kata yang dipilih:  intelligence\n",
      "Probability:  0.009554140127388535\n"
     ]
    }
   ],
   "source": [
    "bigram_key = prob_bigram.keys() #Langkah 1\n",
    "bigram_start = []\n",
    "bigram_word = ''\n",
    "nilai_prob = []\n",
    "max_prob = 0\n",
    "index_terakhir = len(input_words)-1 #Langkah 2\n",
    "last_word = input_words[index_terakhir][1] #Langkah 3\n",
    "print(last_word)\n",
    "for j in bigram_key: #Langkah 4\n",
    "    if j[0] == last_word: \n",
    "        bigram_start.append(j[1]) #Langkah 4a\n",
    "        nilai_prob.append(prob_bigram[j]) #Langkah 4b\n",
    "for x in range(len(nilai_prob)): #Langkah 6\n",
    "    if nilai_prob[x] > max_prob: #Langkah 6\n",
    "        max_prob = nilai_prob[x] #Langkah 6\n",
    "        bigram_word = bigram_start[x] #Langkah 6\n",
    "print(bigram_start) #Langkah 7\n",
    "print(nilai_prob) #Langkah 7\n",
    "print('Kata yang dipilih: ', bigram_word) #Langkah 8\n",
    "print('Probability: ',max_prob) #Langkah 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hasil Pengujian \n",
    "1. Input: apakah pada zaman ini artificial\n",
    "<center> ![](files/artificial.JPG) </center>\n",
    "2. Input: pengertian dari artificial intelligence adalah suatu kecerdasan\n",
    "<center> ![](files/kecerdasan.JPG) </center>\n",
    "3. Input: salah satu bidang artificial intelligence adalah pada bagian neural\n",
    "<center> ![](files/neural.JPG) </center>\n",
    "4. Input: pada zaman sekarang sifat manusia\n",
    "<center> ![](files/manusia.JPG) </center>\n",
    "5. Input: saya mau tidur\n",
    "<center> ![](files/tidur.JPG) </center>\n",
    "6. Input: besok saya mau makan\n",
    "<center> ![](files/makan.JPG) </center>\n",
    "7. Input: saya sangat suka sekali makan ayam\n",
    "<center> ![](files/ayam.JPG) </center>\n",
    "8. Input: bagaimana jika anda tidak tahu\n",
    "<center> ![](files/tahu.JPG) </center>\n",
    "9. Input: jika manusia zaman dahulu merupakan\n",
    "<center> ![](files/merupakan.JPG) </center>\n",
    "10. Input: Bagaimana perkembangan Indonesia dalam bidang teknologi\n",
    "<center> ![](files/teknologi.JPG) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uji Preplexity Kalimat\n",
    "Pada tahap ini akan dilakukan pengujian nilai preplexity dari suatu kalimat, untuk mengetahui seberapa mampu bigram model yang dibangun dapat mengetahui sequence kata yang ada pada data test. Pada buku Speech and Language Processing oleh Jurafsky dan Martin, dikatakan bahwa:\n",
    "* Higher probability means lower Perplexity\n",
    "* The more information, the lower preplexity\n",
    "* Lower preplexity means a better model\n",
    "* The lower the preplexity, the closer we are to the true model\n",
    "* Rumus: \n",
    "<center> ![](files/preplexity.JPG) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Probability with Laplace Smoothing\n",
    "Langkah-langkah:\n",
    "1. Lakukan pengecekan pada setiap indeks bigram pada array bigram model. Selama looping maka:\n",
    "    * Jika bigram kalimat dengan indeks ke-i terdapat pada dictionary probability bigram corpus dengan key yaitu bigram kalimat indeks-i maka: \n",
    "    (a) nilai total probabilitas dikalikan dengan nilai probability dari dictionary bigram corpus dengan key tersebut \n",
    "    (b) nilai perhitungan preplexity dikalikan dengan (1 / nilai probability dictionary bigram corpus dengan key tersebut)\n",
    "    * Jika tidak ada, maka:\n",
    "    (a) Lakukan pengecekan apakah kata pertama pada bigram kalimat dengan indeks-i tersebut tidak ada di dictionary frekuensi unigram corpus, jika tidak ada maka kata pertama tersebut akan ditambahkan kedalam dictionary dengan nilai kemunculan yaitu 1\n",
    "    (b) Lalu, nilai probabilistik dari kata pertama tersebut akan dihitung dengan rumus 1 / nilai kemunculan pada dictionary unigram corpus + jumlah kata dalam dictionary unigram corpus\n",
    "    (c) Hitung nilai total probabilitas nya dengan mengalikan nilai total probabilitas yang sudah ada dikali nilai probabilistik yang telah dihitung pada langkah b\n",
    "    (d) Nilai perhitungan preplexity yang sudah ada dikali 1 / nilai probabilistik pada langkah b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_probability_addone(input_words):\n",
    "    total_probabilitas_addone = 1.0\n",
    "    preplexity_addone = 1.0\n",
    "    for i in range(len(input_words)): #Langkah 1\n",
    "        if input_words[i] in prob_bigram: #Langkah 1a\n",
    "            #print(str(input_words[i]) + '  ' + str(prob_bigram[input_words[i]]) + '\\n')\n",
    "            total_probabilitas_addone =  total_probabilitas_addone * prob_bigram[input_words[i]] #Langkah 1.a.a\n",
    "            preplexity_addone = preplexity_addone * (1/prob_bigram[input_words[i]]) #Langkah 1.a.b\n",
    "        else: #Langkah 1b\n",
    "            if input_words[i][0] not in freq_unigram: #Langkah 1.b.a\n",
    "                freq_unigram[input_words[i][0]] = 1\n",
    "            probabilistik = (1) / (freq_unigram[input_words[i][0]] + len(freq_unigram)) #Langkah 1.b.b\n",
    "            total_probabilitas_addone =  total_probabilitas_addone * probabilistik #Langkah 1.b.c\n",
    "            preplexity_addone = preplexity_addone * (1/probabilistik) #Langkah 1.b.d\n",
    "            #print(str(input_words[i]) + ' ' + str(probabilistik) + '\\n')\n",
    "    return total_probabilitas_addone, preplexity_addone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Probability with Reconstituted Counts\n",
    "Langkah - langkah: \n",
    "1. Lakukan pengecekan pada setiap indeks bigram pada array bigram model. Selama looping maka:\n",
    "    * Jika bigram kalimat dengan indeks ke-i terdapat pada dictionary probability cstar bigram corpus dengan key yaitu bigram kalimat indeks-i maka: \n",
    "    (a) nilai total probabilitas dikalikan dengan nilai probability dari dictionary cstar bigram corpus dengan key tersebut \n",
    "    (b) nilai perhitungan preplexity dikalikan dengan (1 / nilai probability dictionary cstar bigram corpus dengan key tersebut)\n",
    "    * Jika tidak ada, maka:\n",
    "    (a) Lakukan pengecekan apakah kata pertama pada bigram kalimat dengan indeks-i tersebut tidak ada di dictionary frekuensi unigram corpus, jika tidak ada maka kata pertama tersebut akan ditambahkan kedalam dictionary dengan nilai kemunculan yaitu 1\n",
    "    (b) Lalu, nilai probabilistik dari kata pertama tersebut akan dihitung dengan rumus : 1 dikali nilai kemunculan pada dictionary unigram corpus / (nilai kemunculan pada dictionary unigram corpus + jumlah kata dalam dictionary unigram corpus)\n",
    "    (c) Hitung nilai total probabilitas nya dengan mengalikan nilai total probabilitas yang sudah ada dikali nilai probabilistik yang telah dihitung pada langkah b\n",
    "    (d) Nilai perhitungan preplexity yang sudah ada dikali 1 / nilai probabilistik pada langkah b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_probabilitas_cstar(input_words):\n",
    "    total_probabilitas_cstar = 1.0\n",
    "    preplexity_cstar = 1.0\n",
    "    for i in range(len(input_words)): #Langkah 1\n",
    "        if input_words[i] in cstar_bigram: #Langkah 1.a\n",
    "            #print(str(input_words[i]) + '  ' + str(cstar_bigram[input_words[i]]) +  '\\n') \n",
    "            total_probabilitas_cstar = total_probabilitas_cstar * (cstar_bigram[input_words[i]]) #Langkah 1.a.a\n",
    "            preplexity_cstar = preplexity_cstar * (1/cstar_bigram[input_words[i]]) #Langkah 1.a.b\n",
    "        else: #Langkah 1.b\n",
    "            if input_words[i][0] not in freq_unigram:\n",
    "                freq_unigram[input_words[i][0]] = 1 #Langkah 1.b.a\n",
    "            cstar = 1 * freq_unigram[input_words[i][0]] / (freq_unigram[input_words[i][0]] + len(freq_unigram)) #Langkah 1.b.b\n",
    "            total_probabilitas_cstar = total_probabilitas_cstar * (cstar) #Langkah 1.b.c\n",
    "            preplexity_cstar = preplexity_cstar * (1/cstar) #Langkah 1.b.d\n",
    "            #print(str(input_words[i]) + ' ' + str(cstar) + '\\n') \n",
    "    return total_probabilitas_cstar, preplexity_cstar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nilai Preplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nilaiPreplexity(preplexity, input_words):\n",
    "    nilai_preplexity = pow(preplexity, 1/(float(len(input_words))))\n",
    "    return nilai_preplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pengujian Preplexity dengan Kalimat Terdefinisi:\n",
    "Langkah - langkah: \n",
    "1. Mendefinisikan 5 kalimat yang akan di uji modelnya terhadap corpus\n",
    "2. Pilih kalimat yang ingin di uji\n",
    "3. Generalisasi seluruh huruf pada kalimat yang dipilih menjadi huruf kecil\n",
    "4. Melakukan tokenisasi terhadap setiap kata dalam kalimat\n",
    "5. Membuat hasil tokenisasi kedalam bigram agar dapat diuji sesuai dengan bigram model dan disimpan kedalam array\n",
    "6. Menampilkan array bigram model dari kalimat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_kalimat(kalimat=''):\n",
    "    input_words  = []\n",
    "    kalimat = kalimat.lower()\n",
    "    token = nltk.word_tokenize(kalimat)\n",
    "    for i in range(len(token)-1):\n",
    "        input_words.append((token[i], token[i+1]))\n",
    "    return input_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kalima1, kalimat2, dst merupakan langkah 1\n",
    "kalimat1 = bigram_kalimat('Selain itu, aplikasi satu ini juga memiliki banyak fitur pendukung, seperti tanda adanya kemacetan hingga kecelakaan yang sedang terjadi.')\n",
    "kalimat2 = bigram_kalimat('Seperti dikutip dari laman Merdeka.com, Sabtu (5/5/2018), berikut beberapa teknologi yang ternyata memiliki peran besar di dalam kehidupan manusia.')\n",
    "kalimat3 = bigram_kalimat('Uniknya, aplikasi ini akan berfungsi hanya dengan meletakkan jari telunjuk di atas kamera.')\n",
    "kalimat4 = bigram_kalimat('Dan tanpa kamu sadari, peranan urusan pekerjaan hingga mencari makanan dan tempat liburan pun sangat membantu penggunanya.')\n",
    "kalimat5 = bigram_kalimat('Semua informasi sudah tertera dari yang mudah sampai yang sulit sekalipun.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Model Kalimat:  [('selain', 'itu'), ('itu', ','), (',', 'aplikasi'), ('aplikasi', 'satu'), ('satu', 'ini'), ('ini', 'juga'), ('juga', 'memiliki'), ('memiliki', 'banyak'), ('banyak', 'fitur'), ('fitur', 'pendukung'), ('pendukung', ','), (',', 'seperti'), ('seperti', 'tanda'), ('tanda', 'adanya'), ('adanya', 'kemacetan'), ('kemacetan', 'hingga'), ('hingga', 'kecelakaan'), ('kecelakaan', 'yang'), ('yang', 'sedang'), ('sedang', 'terjadi'), ('terjadi', '.')]\n",
      "Total Probabilitas addOne:  2.1811881448117257e-71\n",
      "Total Probabilitas cStar:  2.2994681693220736e-33\n",
      "Nilai Preplexity with addOne:  2316.4564338507075\n",
      "Nilai Preplexity with addOne:  35.82681646795164\n"
     ]
    }
   ],
   "source": [
    "total_probabilitas_addone1 = 0\n",
    "preplexity_addone1 = 0\n",
    "total_probabilitas_cstar1= 0\n",
    "preplexity_cstar1 = 0\n",
    "nilai_preplexity_addone1 = 0\n",
    "nilai_preplexity_cstar1 = 0\n",
    "total_probabilitas_addone1, preplexity_addone1 = get_total_probability_addone(kalimat1)\n",
    "total_probabilitas_cstar1, preplexity_cstar1 = get_total_probabilitas_cstar(kalimat1)\n",
    "nilai_preplexity_addone1 = get_nilaiPreplexity(preplexity_addone1, kalimat1)\n",
    "nilai_preplexity_cstar1 = get_nilaiPreplexity(preplexity_cstar1, kalimat1)\n",
    "print('Bigram Model Kalimat: ',kalimat1)\n",
    "print('Total Probabilitas addOne: ', total_probabilitas_addone1)\n",
    "print('Total Probabilitas cStar: ', total_probabilitas_cstar1)\n",
    "print('Nilai Preplexity with addOne: ',nilai_preplexity_addone1)\n",
    "print('Nilai Preplexity with addOne: ',nilai_preplexity_cstar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Model Kalimat:  [('seperti', 'dikutip'), ('dikutip', 'dari'), ('dari', 'laman'), ('laman', 'merdeka.com'), ('merdeka.com', ','), (',', 'sabtu'), ('sabtu', '('), ('(', '5/5/2018'), ('5/5/2018', ')'), (')', ','), (',', 'berikut'), ('berikut', 'beberapa'), ('beberapa', 'teknologi'), ('teknologi', 'yang'), ('yang', 'ternyata'), ('ternyata', 'memiliki'), ('memiliki', 'peran'), ('peran', 'besar'), ('besar', 'di'), ('di', 'dalam'), ('dalam', 'kehidupan'), ('kehidupan', 'manusia'), ('manusia', '.')]\n",
      "Total Probabilitas addOne:  1.6161330436868827e-78\n",
      "Total Probabilitas cStar:  7.018553910956746e-36\n",
      "Nilai Preplexity with addOne:  2411.2382573200093\n",
      "Nilai Preplexity with addOne:  33.76167738939125\n"
     ]
    }
   ],
   "source": [
    "total_probabilitas_addone2 = 0\n",
    "preplexity_addone2 = 0\n",
    "total_probabilitas_cstar2= 0\n",
    "preplexity_cstar2 = 0\n",
    "nilai_preplexity_addone2 = 0\n",
    "nilai_preplexity_cstar2 = 0\n",
    "total_probabilitas_addone2, preplexity_addone2 = get_total_probability_addone(kalimat2)\n",
    "total_probabilitas_cstar2, preplexity_cstar2 = get_total_probabilitas_cstar(kalimat2)\n",
    "nilai_preplexity_addone2 = get_nilaiPreplexity(preplexity_addone2, kalimat2)\n",
    "nilai_preplexity_cstar2 = get_nilaiPreplexity(preplexity_cstar2, kalimat2)\n",
    "print('Bigram Model Kalimat: ',kalimat2)\n",
    "print('Total Probabilitas addOne: ', total_probabilitas_addone2)\n",
    "print('Total Probabilitas cStar: ', total_probabilitas_cstar2)\n",
    "print('Nilai Preplexity with addOne: ',nilai_preplexity_addone2)\n",
    "print('Nilai Preplexity with addOne: ',nilai_preplexity_cstar2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Model Kalimat:  [('uniknya', ','), (',', 'aplikasi'), ('aplikasi', 'ini'), ('ini', 'akan'), ('akan', 'berfungsi'), ('berfungsi', 'hanya'), ('hanya', 'dengan'), ('dengan', 'meletakkan'), ('meletakkan', 'jari'), ('jari', 'telunjuk'), ('telunjuk', 'di'), ('di', 'atas'), ('atas', 'kamera'), ('kamera', '.')]\n",
      "Total Probabilitas addOne:  1.0017204943005584e-49\n",
      "Total Probabilitas cStar:  1.5313528015665131e-27\n",
      "Nilai Preplexity with addOne:  3161.889397882586\n",
      "Nilai Preplexity with addOne:  82.29089150775812\n"
     ]
    }
   ],
   "source": [
    "total_probabilitas_addone3 = 0\n",
    "preplexity_addone3 = 0\n",
    "total_probabilitas_cstar3= 0\n",
    "preplexity_cstar3 = 0\n",
    "nilai_preplexity_addone3 = 0\n",
    "nilai_preplexity_cstar3 = 0\n",
    "total_probabilitas_addone3, preplexity_addone3 = get_total_probability_addone(kalimat3)\n",
    "total_probabilitas_cstar3, preplexity_cstar3 = get_total_probabilitas_cstar(kalimat3)\n",
    "nilai_preplexity_addone3 = get_nilaiPreplexity(preplexity_addone3, kalimat3)\n",
    "nilai_preplexity_cstar3 = get_nilaiPreplexity(preplexity_cstar3, kalimat3)\n",
    "print('Bigram Model Kalimat: ',kalimat3)\n",
    "print('Total Probabilitas addOne: ', total_probabilitas_addone3)\n",
    "print('Total Probabilitas cStar: ', total_probabilitas_cstar3)\n",
    "print('Nilai Preplexity with addOne: ',nilai_preplexity_addone3)\n",
    "print('Nilai Preplexity with addOne: ',nilai_preplexity_cstar3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Model Kalimat:  [('dan', 'tanpa'), ('tanpa', 'kamu'), ('kamu', 'sadari'), ('sadari', ','), (',', 'peranan'), ('peranan', 'urusan'), ('urusan', 'pekerjaan'), ('pekerjaan', 'hingga'), ('hingga', 'mencari'), ('mencari', 'makanan'), ('makanan', 'dan'), ('dan', 'tempat'), ('tempat', 'liburan'), ('liburan', 'pun'), ('pun', 'sangat'), ('sangat', 'membantu'), ('membantu', 'penggunanya'), ('penggunanya', '.')]\n",
      "Total Probabilitas addOne:  3.317990099247425e-67\n",
      "Total Probabilitas cStar:  7.125159111221944e-41\n",
      "Nilai Preplexity with addOne:  4934.972278859382\n",
      "Nilai Preplexity with addOne:  169.9809694570859\n"
     ]
    }
   ],
   "source": [
    "total_probabilitas_addone4 = 0\n",
    "preplexity_addone4 = 0\n",
    "total_probabilitas_cstar4= 0\n",
    "preplexity_cstar4 = 0\n",
    "nilai_preplexity_addone4 = 0\n",
    "nilai_preplexity_cstar4 = 0\n",
    "total_probabilitas_addone4, preplexity_addone4 = get_total_probability_addone(kalimat4)\n",
    "total_probabilitas_cstar4, preplexity_cstar4 = get_total_probabilitas_cstar(kalimat4)\n",
    "nilai_preplexity_addone4 = get_nilaiPreplexity(preplexity_addone4, kalimat4)\n",
    "nilai_preplexity_cstar4 = get_nilaiPreplexity(preplexity_cstar4, kalimat4)\n",
    "print('Bigram Model Kalimat: ',kalimat4)\n",
    "print('Total Probabilitas addOne: ', total_probabilitas_addone4)\n",
    "print('Total Probabilitas cStar: ', total_probabilitas_cstar4)\n",
    "print('Nilai Preplexity with addOne: ',nilai_preplexity_addone4)\n",
    "print('Nilai Preplexity with addOne: ',nilai_preplexity_cstar4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Model Kalimat:  [('semua', 'informasi'), ('informasi', 'sudah'), ('sudah', 'tertera'), ('tertera', 'dari'), ('dari', 'yang'), ('yang', 'mudah'), ('mudah', 'sampai'), ('sampai', 'yang'), ('yang', 'sulit'), ('sulit', 'sekalipun'), ('sekalipun', '.')]\n",
      "Total Probabilitas addOne:  6.074916420034134e-41\n",
      "Total Probabilitas cStar:  2.2472560048773456e-22\n",
      "Nilai Preplexity with addOne:  4529.411623498313\n",
      "Nilai Preplexity with addOne:  92.90339533140973\n"
     ]
    }
   ],
   "source": [
    "total_probabilitas_addone5 = 0\n",
    "preplexity_addone5 = 0\n",
    "total_probabilitas_cstar5= 0\n",
    "preplexity_cstar5 = 0\n",
    "nilai_preplexity_addone5 = 0\n",
    "nilai_preplexity_cstar5 = 0\n",
    "total_probabilitas_addone5, preplexity_addone5 = get_total_probability_addone(kalimat5)\n",
    "total_probabilitas_cstar5, preplexity_cstar5 = get_total_probabilitas_cstar(kalimat5)\n",
    "nilai_preplexity_addone5 = get_nilaiPreplexity(preplexity_addone5, kalimat5)\n",
    "nilai_preplexity_cstar5 = get_nilaiPreplexity(preplexity_cstar5, kalimat5)\n",
    "print('Bigram Model Kalimat: ',kalimat5)\n",
    "print('Total Probabilitas addOne: ', total_probabilitas_addone5)\n",
    "print('Total Probabilitas cStar: ', total_probabilitas_cstar5)\n",
    "print('Nilai Preplexity with addOne: ',nilai_preplexity_addone5)\n",
    "print('Nilai Preplexity with addOne: ',nilai_preplexity_cstar5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hasil Pengujian Preplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kalimat</th>\n",
       "      <th>Total Probabilitas addOne</th>\n",
       "      <th>Nilai Preplexity addOne</th>\n",
       "      <th>Total Probabilitas cstar</th>\n",
       "      <th>Nilai Preplexity cstar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kalimat 1</td>\n",
       "      <td>2.181188e-71</td>\n",
       "      <td>2316.456434</td>\n",
       "      <td>2.299468e-33</td>\n",
       "      <td>35.826816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kalimat 2</td>\n",
       "      <td>1.616133e-78</td>\n",
       "      <td>2411.238257</td>\n",
       "      <td>7.018554e-36</td>\n",
       "      <td>33.761677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kalimat 3</td>\n",
       "      <td>1.001720e-49</td>\n",
       "      <td>3161.889398</td>\n",
       "      <td>1.531353e-27</td>\n",
       "      <td>82.290892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kalimat 4</td>\n",
       "      <td>3.317990e-67</td>\n",
       "      <td>4934.972279</td>\n",
       "      <td>7.125159e-41</td>\n",
       "      <td>169.980969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalimat 5</td>\n",
       "      <td>6.074916e-41</td>\n",
       "      <td>4529.411623</td>\n",
       "      <td>2.247256e-22</td>\n",
       "      <td>92.903395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Kalimat  Total Probabilitas addOne  Nilai Preplexity addOne  \\\n",
       "0  Kalimat 1               2.181188e-71              2316.456434   \n",
       "1  Kalimat 2               1.616133e-78              2411.238257   \n",
       "2  Kalimat 3               1.001720e-49              3161.889398   \n",
       "3  Kalimat 4               3.317990e-67              4934.972279   \n",
       "4  Kalimat 5               6.074916e-41              4529.411623   \n",
       "\n",
       "   Total Probabilitas cstar  Nilai Preplexity cstar  \n",
       "0              2.299468e-33               35.826816  \n",
       "1              7.018554e-36               33.761677  \n",
       "2              1.531353e-27               82.290892  \n",
       "3              7.125159e-41              169.980969  \n",
       "4              2.247256e-22               92.903395  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "raw_data = {'Kalimat' : ['Kalimat 1', 'Kalimat 2', 'Kalimat 3', 'Kalimat 4', 'Kalimat 5'],\n",
    "           'Total Probabilitas addOne' : [total_probabilitas_addone1, total_probabilitas_addone2, total_probabilitas_addone3, total_probabilitas_addone4, total_probabilitas_addone5],\n",
    "           'Nilai Preplexity addOne': [nilai_preplexity_addone1, nilai_preplexity_addone2, nilai_preplexity_addone3, nilai_preplexity_addone4, nilai_preplexity_addone5],\n",
    "           'Total Probabilitas cstar' : [total_probabilitas_cstar1, total_probabilitas_cstar2, total_probabilitas_cstar3, total_probabilitas_cstar4, total_probabilitas_cstar5],\n",
    "           'Nilai Preplexity cstar': [nilai_preplexity_cstar1,nilai_preplexity_cstar2, nilai_preplexity_cstar3, nilai_preplexity_cstar4, nilai_preplexity_cstar5]}\n",
    "df = pd.DataFrame(raw_data, columns=['Kalimat', 'Total Probabilitas addOne', 'Nilai Preplexity addOne','Total Probabilitas cstar','Nilai Preplexity cstar'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> EVALUATION <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Analisis Hasil Pengujian Prediksi Kemunculan Kata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada proses pengujian prediksi kemunculan kata, diberikan 10 kata terdefinisi untuk diuji kata apa yang akan keluar setelah kata tersebut. Adapun 10 kata tersebut adalah: \n",
    "1. Kata **artificial** ; pasangan: **intelligence**\n",
    "2. Kata **kecerdasan**; pasangan: **buatan**\n",
    "3. Kata **neural** ; pasangan: **neutwork**\n",
    "4. Kata **manusia**; pasangan: **.**\n",
    "5. Kata **tidur**; pasangan: **,**\n",
    "6. Kata **makan**; pasangan: **mingguan**\n",
    "7. Kata **ayam**; pasangan: -\n",
    "8. Kata **tahu**; pasangan: **bahwa**\n",
    "9. Kata **merupakan**; pasangan: **sebuah**\n",
    "10. Kata **teknologi** ; pasangan: **ai**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis:\n",
    "* Hasil pengujian untuk kata 1,2, dan 3 menunjukkan bahwa ketiga kata tersebut adalah kata yang paling sering muncul di dalam artikel sehingga pasangan kata yang muncul sangat sesuai dengan kata sebelumnya yaitu kata artificial, kecerdasan, dan neural\n",
    "* Hasil pengujian untuk kata 4 dan 5 cukup general, karena yang muncul setelah dua kata tersebut bukan berupa kata tetapi berupa **regular expression** sehingga dapat dikatakan bahwa didalam artikel, kata **manusia** bisa merupakan akhir dari suatu kalimat dan kata **tidur** biasanya diikuti dengan tanda baca\n",
    "* Hasil pengujian kata ke 6 yaitu makan hanya menghasilkan satu kemungkinan kata yaitu **mingguan** sehingga dapat dikatakan bahwa dalam artikel dengan topik mengenai kecerdasan buatan atau artificial intelligence, sangat jarang menggunakan kata **makan**\n",
    "* Hasil pengujian kata ke 7 yaitu ayam tidak menghasil kemungkinan apapun, sehingga dapat dikatakan bahwa pada corpus yang dibangun tidak ada satupun yang menyebutkan kata **ayam**\n",
    "* Hasil pengujian kata ke 8 dimana kata tahu merupakan kata yang cenderung memiliki ambiguitas karena dapat memiliki 2 arti yang berbeda, dari hasil pengujian kata tahu pada corpus dianggap sebagai kata kerja karena hasil kata setelahnya berupa kata sifat  yaitu **bahwa**\n",
    "* Hasil pengujian kata ke 9 dan 10 menghasilkan pasangan kata yang cukup baik karena memiliki kesinambungan dengankata sebelumnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analisis Hasil Pengujian Preplexity pada Kalimat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada proses pengujian preplexity kalimat, diberikan 5 kalimat terdefinisi untuk di uji nilai preplexity dari tiap kalimat tersebut. Pengujian preplexity juga menggunakan dua metode yaitu nilai preplexity pada nilai probabilitas dengan penambahan **laplace smoothing** dan nilai probabilitas dengan penambahan **reconstituted counts**. Adapun 5 kalimat yang terdefinisi adalah sebagai berikut:\n",
    "* Kalimat 1: Seperti dikutip dari laman Merdeka.com, Sabtu (5/5/2018), berikut beberapa teknologi yang ternyata memiliki peran besar di dalam kehidupan manusia. Jumlah kata: 21 kata\n",
    "* Kalimat 2: Selain itu, aplikasi satu ini juga memiliki banyak fitur pendukung, seperti tanda adanya kemacetan hingga kecelakaan yang sedang terjadi. Jumlah kata: 23 kata\n",
    "* Kalimat 3: Uniknya, aplikasi ini akan berfungsi hanya dengan meletakkan jari telunjuk di atas kamera. Jumlah kata: 14 kata\n",
    "* Kalimat 4 : Dan tanpa kamu sadari, peranan urusan pekerjaan hingga mencari makanan dan tempat liburan pun sangat membantu penggunanya. Jumlah kata: 18 kata\n",
    "* Kalimat 5 : Semua informasi sudah tertera dari yang mudah sampai yang sulit sekalipun. Jumlah kata: 11 kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kalimat</th>\n",
       "      <th>Total Probabilitas addOne</th>\n",
       "      <th>Nilai Preplexity addOne</th>\n",
       "      <th>Total Probabilitas cstar</th>\n",
       "      <th>Nilai Preplexity cstar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kalimat 1</td>\n",
       "      <td>2.181188e-71</td>\n",
       "      <td>2316.456434</td>\n",
       "      <td>2.299468e-33</td>\n",
       "      <td>35.826816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kalimat 2</td>\n",
       "      <td>1.616133e-78</td>\n",
       "      <td>2411.238257</td>\n",
       "      <td>7.018554e-36</td>\n",
       "      <td>33.761677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kalimat 3</td>\n",
       "      <td>1.001720e-49</td>\n",
       "      <td>3161.889398</td>\n",
       "      <td>1.531353e-27</td>\n",
       "      <td>82.290892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kalimat 4</td>\n",
       "      <td>3.317990e-67</td>\n",
       "      <td>4934.972279</td>\n",
       "      <td>7.125159e-41</td>\n",
       "      <td>169.980969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalimat 5</td>\n",
       "      <td>6.074916e-41</td>\n",
       "      <td>4529.411623</td>\n",
       "      <td>2.247256e-22</td>\n",
       "      <td>92.903395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Kalimat  Total Probabilitas addOne  Nilai Preplexity addOne  \\\n",
       "0  Kalimat 1               2.181188e-71              2316.456434   \n",
       "1  Kalimat 2               1.616133e-78              2411.238257   \n",
       "2  Kalimat 3               1.001720e-49              3161.889398   \n",
       "3  Kalimat 4               3.317990e-67              4934.972279   \n",
       "4  Kalimat 5               6.074916e-41              4529.411623   \n",
       "\n",
       "   Total Probabilitas cstar  Nilai Preplexity cstar  \n",
       "0              2.299468e-33               35.826816  \n",
       "1              7.018554e-36               33.761677  \n",
       "2              1.531353e-27               82.290892  \n",
       "3              7.125159e-41              169.980969  \n",
       "4              2.247256e-22               92.903395  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis:\n",
    "1. Jika dilihat pada tabel diatas, dengan menggunakan probability laplace smoothing rentang nilai yang diperoleh cukup tinggi yaitu 2000 s.d 4000 , hal ini bisa saja terjadi diakibatkan oleh penambahan jumlah satu pada seluruh kemungkinan kata yang ada tanpa memperhatikan jumlah seluruh kata pada corpus yang dibangun. Sehingga, dengan laplace smoothing maka nilai probability pada bigram model menjadi sangat besar. Dapat dilihat pada tabel **total probabilitas add one**\n",
    "2. Pada probability cstar, nilai preplexity yang diperoleh tidak begitu tinggi, yaitu 50 s.d 250 , hal ini terjadi karena nilai dari tiap jumlah kemungkinan kata di distribusikan ke nilai kemunculan kata yang bernilai 0 tanpa merubah jumlah total dari keseluruhan kata. Sehingga, dengan reconstituted counts maka nilai probability pada bigram model tidak sebesar pada nilai probability pada laplace smoothing, dapat dilihat pada tabel **total probabilitas cstar**\n",
    "3. Jika dilihat terdapat sedikit perbedaan urutan model kalimat mulai dari yang paling mendekati language modelling dari corpus yang dibangun hingga yang sangat jauh dari language modelling corpus, yaitu.\n",
    "    * Nilai preplexity dengan laplace smoothing memiliki urutan yaitu kalimat 1 - kalimat 2 - kalimat 3 - kalimat 5 - kalimat 4\n",
    "    * Nilai preplexity dengan cstar memiliki urutan yaitu kalimat 2 - kalimat 1 - kalimat 3 - kalimat 5 - kalimat 4\n",
    "4. Dapat dikatakan bahwa dengan menggunakan nilai probabilitas laplace smoothing, model kalimat yang paling mendekati dengan language modelling corpus adalah kalimat 1 (nilai preplexity terkecil). Sedangkan, dengan menggunakan nilai probabilitas cstar maka model kalimat yang paling mendekati dengan language modelling corpus adalah kalimat 2 (nilai preplexity terkecil).\n",
    "5. Model kalimat yang paling menjauhi dan sulit untuk digambarkan oleh language modelling corpus adalah kalimat 4 (nilai preplexity terbesar)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
